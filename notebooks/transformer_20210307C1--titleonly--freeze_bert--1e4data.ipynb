{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRFX = \"transformer_20210307C1\"\n",
    "PRFX_PRP = 'prep_20210307B1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar  7 17:49:16 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   35C    P0    24W / 300W |     11MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=goRmGIRI5cfC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:8080/notebooks/git/product-category/notebooks/prep_20210304A1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = \"/data/git/product-category\"\n",
    "p_out = f'{HOME}/data/{PRFX}'\n",
    "!mkdir -p {p_out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = int(1e4)\n",
    "DATA2USE = f'{HOME}/data/data_sample_{sz}__{PRFX_PRP}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n",
      "CPU times: user 8.43 ms, sys: 37 Âµs, total: 8.47 ms\n",
      "Wall time: 6.83 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>is_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Home &amp; Kitchen|Home Dcor|Mirrors|Mirror Sets</td>\n",
       "      <td>Eastland 16&amp;quot; Round Beveled Centerpiece Ta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Patio, Lawn &amp; Garden|Outdoor Power Tools|Repla...</td>\n",
       "      <td>AZ Patio Heaters Natural Gas Hose, Quick Conne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Clothing, Shoes &amp; Jewelry|Girls|Clothing|Sleep...</td>\n",
       "      <td>AME Sleepwear Little Girls'  Bubble Guppies Ni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              category  \\\n",
       "331       Home & Kitchen|Home Dcor|Mirrors|Mirror Sets   \n",
       "772  Patio, Lawn & Garden|Outdoor Power Tools|Repla...   \n",
       "255  Clothing, Shoes & Jewelry|Girls|Clothing|Sleep...   \n",
       "\n",
       "                                                 title  is_validation  \n",
       "331  Eastland 16&quot; Round Beveled Centerpiece Ta...              1  \n",
       "772  AZ Patio Heaters Natural Gas Hose, Quick Conne...              0  \n",
       "255  AME Sleepwear Little Girls'  Bubble Guppies Ni...              1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# df = pd.read_csv(f'../data/data__{PRFX_PRP}.csv')\n",
    "# df = pd.read_csv(f'{HOME}/data/data_sample__{PRFX_PRP}.csv')\n",
    "df = pd.read_csv(DATA2USE, nrows=1000)\n",
    "print(df.shape)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA2USE, nrows=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(i2cat) 10\n",
      "Accessories|Automotive|Books|Clothing|Clothing, Shoes & Jewelry|Electronics|Home & Kitchen|Sports & Outdoors|Toys & Games|Women\n"
     ]
    }
   ],
   "source": [
    "MIN_CNT = 50\n",
    "cat2cnt = Counter((j for i in df.category.apply(lambda x: x.split('|')) for j in i))\n",
    "i2cat = sorted(k for k,v in cat2cnt.items() if v>MIN_CNT)\n",
    "cat2i = {v:k for k,v in enumerate(i2cat)}\n",
    "\n",
    "print(\"len(i2cat)\", len(i2cat))\n",
    "print(\"|\".join(i2cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Books', 213),\n",
       " ('Clothing, Shoes & Jewelry', 171),\n",
       " ('Women', 103),\n",
       " ('Home & Kitchen', 89),\n",
       " ('Clothing', 83),\n",
       " ('Sports & Outdoors', 64),\n",
       " ('Automotive', 64),\n",
       " ('Accessories', 63),\n",
       " ('Electronics', 61),\n",
       " ('Toys & Games', 52),\n",
       " ('Men', 47),\n",
       " ('Kindle Store', 41),\n",
       " ('Kindle eBooks', 40),\n",
       " ('Tools & Home Improvement', 40),\n",
       " ('Shoes', 40),\n",
       " ('Sports & Fitness', 35),\n",
       " ('Cell Phones & Accessories', 34),\n",
       " ('Replacement Parts', 33),\n",
       " ('Imported', 32),\n",
       " ('Patio, Lawn & Garden', 28)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat2cnt.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import pytorch_lightning as pl\n",
    "from transformers.optimization import AdamW\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "def mk_tensors(txt, tokenizer, max_seq_length):\n",
    "    tok_res = tokenizer(\n",
    "        txt, truncation=True, padding='max_length', max_length=max_seq_length\n",
    "    )\n",
    "    input_ids = tok_res[\"input_ids\"]\n",
    "    attention_mask = tok_res[\"attention_mask\"]\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    return input_ids, attention_mask\n",
    "\n",
    "def mk_ds(txt, tokenizer, max_seq_length, ys):\n",
    "    input_ids, attention_mask = mk_tensors(txt, tokenizer, max_seq_length)\n",
    "    return TensorDataset(input_ids, \n",
    "                         attention_mask, \n",
    "                         torch.tensor(ys)) \n",
    "\n",
    "class PCDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 model_name_or_path, \n",
    "                 max_seq_length, \n",
    "                 min_products_for_category,\n",
    "                 train_batch_size,\n",
    "                 val_batch_size,\n",
    "                 dataloader_num_workers,\n",
    "                 data_file_path=None,\n",
    "                 dataframe=None):\n",
    "        super().__init__()\n",
    "        self.data_file_path = data_file_path\n",
    "        self.dataframe = dataframe\n",
    "        self.min_products_for_category = min_products_for_category\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.val_batch_size = val_batch_size\n",
    "        self.dataloader_num_workers = dataloader_num_workers\n",
    "        self.num_classes = None\n",
    "      \n",
    "    def prepare_data(self):\n",
    "        #prepare_data is called from a single process (e.g. GPU 0). Do not use it to assign state (self.x = y).\n",
    "        _ = AutoTokenizer.from_pretrained(self.model_name_or_path)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path)\n",
    "        if self.dataframe is None:\n",
    "            self.dataframe = pd.read_csv(self.data_file_path)\n",
    "            self.dataframe.dropna(inplace=True)\n",
    "\n",
    "        \n",
    "#         self.dataframe = self.dataframe[self.dataframe.title.notna()].copy()\n",
    "        \n",
    "        cats = self.dataframe.category.apply(lambda x: x.split('|'))\n",
    "        cat2cnt = Counter((j for i in cats for j in i))\n",
    "        i2cat = sorted(k for k,v in cat2cnt.items() if v>self.min_products_for_category)\n",
    "        cat2i = {v:k for k,v in enumerate(i2cat)}\n",
    "        self.num_classes = len(i2cat)\n",
    "        self.i2cat, self.cat2i = i2cat, cat2i\n",
    "        \n",
    "        ys = np.zeros((len(self.dataframe), len(i2cat)))\n",
    "        for i,cats in enumerate(self.dataframe.category):\n",
    "            idx_pos = [cat2i[cat] for cat in cats.split('|') if cat in cat2i]\n",
    "            ys[i,idx_pos] = 1\n",
    "        \n",
    "        msk_val = self.dataframe.is_validation==1\n",
    "        self.df_trn = self.dataframe[~msk_val]\n",
    "        self.df_val = self.dataframe[ msk_val]\n",
    "        idx_trn = np.where(~msk_val)[0]\n",
    "        idx_val = np.where( msk_val)[0]\n",
    "        self.ys_trn, self.ys_val = ys[idx_trn], ys[idx_val]\n",
    "        \n",
    "        self.train_dataset = mk_ds(list(self.df_trn.title), self.tokenizer, self.max_seq_length, self.ys_trn)\n",
    "        self.eval_dataset  = mk_ds(list(self.df_val.title), self.tokenizer, self.max_seq_length, self.ys_val)\n",
    "        \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.train_batch_size,\n",
    "            num_workers=self.dataloader_num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.eval_dataset,\n",
    "            batch_size=self.val_batch_size,\n",
    "            num_workers=self.dataloader_num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "def getaccu(logits, ys):\n",
    "    return ((logits>0.).int() == ys).float().mean()\n",
    "\n",
    "class PCModel(pl.LightningModule):\n",
    "    def __init__(self, model_name_or_path, freeze_bert, num_classes, learning_rate, adam_beta1, adam_beta2, adam_epsilon):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.bert = AutoModel.from_pretrained(self.model_name_or_path)\n",
    "        self.freeze_bert = freeze_bert\n",
    "        if freeze_bert==True:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.num_classes = num_classes\n",
    "        self.W = nn.Linear(self.bert.config.hidden_size, self.num_classes)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        #prepare_data is called from a single process (e.g. GPU 0). Do not use it to assign state (self.x = y).\n",
    "        _ = AutoModel.from_pretrained(self.model_name_or_path)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        h = self.bert(input_ids, attention_mask)['last_hidden_state']\n",
    "        h_cls = h[:, 0]\n",
    "        return self.W(h_cls)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, ys = batch    \n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, ys)\n",
    "        accu = getaccu(logits, ys)\n",
    "        self.log('train_loss', loss, on_epoch=True)\n",
    "        self.log('train_accu', accu, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, ys = batch    \n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, ys)\n",
    "        accu = getaccu(logits, ys)\n",
    "        self.log('valid_loss', loss, on_step=False, sync_dist=True)\n",
    "        self.log('valid_accu', accu, on_step=False, sync_dist=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(),\n",
    "                          self.hparams.learning_rate,\n",
    "                          betas=(self.hparams.adam_beta1,\n",
    "                                 self.hparams.adam_beta2),\n",
    "                          eps=self.hparams.adam_epsilon,)\n",
    "        return optimizer    \n",
    "    \n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument('--learning_rate', type=float, default=5e-5)\n",
    "        parser.add_argument('--adam_beta1', type=float, default=0.9)\n",
    "        parser.add_argument('--adam_beta2', type=float, default=0.999)\n",
    "        parser.add_argument('--adam_epsilon', type=float, default=1e-8)\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "\n",
    "parser.add_argument('--model_name_or_path', type=str,\n",
    "                    default=\"distilbert-base-cased\")\n",
    "parser.add_argument('--freeze_bert', action='store_true')\n",
    "parser.add_argument('--max_seq_length', type=int, default=128)\n",
    "parser.add_argument('--min_products_for_category', type=int, default=100)\n",
    "parser.add_argument('--train_batch_size', type=int, default=64)\n",
    "parser.add_argument('--val_batch_size', type=int, default=128)\n",
    "parser.add_argument(\"--dataloader_num_workers\", type=int, default=8)\n",
    "\n",
    "parser = pl.Trainer.add_argparse_args(parser)\n",
    "parser = PCModel.add_model_specific_args(parser)\n",
    "\n",
    "args = parser.parse_args([\n",
    "    '--default_root_dir', p_out,\n",
    "    '--freeze_bert',\n",
    "])\n",
    "\n",
    "\n",
    "data_module = PCDataModule(\n",
    "    model_name_or_path=args.model_name_or_path,\n",
    "#     data_file_path=f'{HOME}/data/data_sample__{PRFX_PRP}.csv',\n",
    "    data_file_path=DATA2USE,\n",
    "    min_products_for_category=args.min_products_for_category,\n",
    "    max_seq_length=args.max_seq_length,\n",
    "    train_batch_size=args.train_batch_size,\n",
    "    val_batch_size=args.val_batch_size,\n",
    "    dataloader_num_workers=args.dataloader_num_workers,\n",
    ")\n",
    "\n",
    "data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 s, sys: 248 ms, total: 1.97 s\n",
      "Wall time: 731 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmodel = PCModel(\n",
    "    model_name_or_path=args.model_name_or_path,\n",
    "    freeze_bert=args.freeze_bert,\n",
    "    num_classes= data_module.num_classes,\n",
    "    learning_rate=args.learning_rate,\n",
    "    adam_beta1=args.adam_beta1,\n",
    "    adam_beta2=args.adam_beta2,\n",
    "    adam_epsilon=args.adam_epsilon,\n",
    ")\n",
    "pcmodel.prepare_data()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dl = data_module.val_dataloader()\n",
    "n=0\n",
    "for dat in dl:\n",
    "    input_ids, attention_mask, ys = dat\n",
    "    logits = pcmodel(input_ids, attention_mask)\n",
    "    accu = getaccu(logits, ys)\n",
    "    print(accu.item())\n",
    "    n+=1\n",
    "    if n>1: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "\n",
    "csv_logger = CSVLogger(p_out, name='csv')\n",
    "tb_logger = TensorBoardLogger(p_out, name='tensorboard')\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, \n",
    "#                                         limit_train_batches=10, limit_val_batches=5, \n",
    "#                                         fast_dev_run=True,\n",
    "                                        max_epochs=10,\n",
    "                                        callbacks=[EarlyStopping(monitor='valid_loss')],\n",
    "                                        stochastic_weight_avg=True,\n",
    "                                        log_gpu_memory=True, \n",
    "                                        gpus=1,\n",
    "                                        logger=[tb_logger,csv_logger],\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "\n",
      "  | Name | Type            | Params\n",
      "-----------------------------------------\n",
      "0 | bert | DistilBertModel | 65.2 M\n",
      "1 | W    | Linear          | 37.7 K\n",
      "-----------------------------------------\n",
      "37.7 K    Trainable params\n",
      "65.2 M    Non-trainable params\n",
      "65.2 M    Total params\n",
      "260.914   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layoutâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/product-category/lib/python3.7/site-packages/pytorch_lightning/core/step_result.py:148: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=device, dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7040862be77a4e89973505b1fc0e332e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), maxâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), mâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), mâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), mâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), mâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), mâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), mâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), mâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), mâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), mâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), mâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(1234)\n",
    "trainer.fit(pcmodel, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/git/product-category/data/transformer_20210307C1/\r\n",
      "/data/git/product-category/data/transformer_20210307C1/tensorboard_csv\r\n",
      "/data/git/product-category/data/transformer_20210307C1/tensorboard_csv/0_0\r\n",
      "/data/git/product-category/data/transformer_20210307C1/tensorboard_csv/0_0/checkpoints\r\n",
      "/data/git/product-category/data/transformer_20210307C1/tensorboard_csv/0_0/checkpoints/epoch=9-step=1329.ckpt\r\n",
      "/data/git/product-category/data/transformer_20210307C1/csv\r\n",
      "/data/git/product-category/data/transformer_20210307C1/csv/version_0\r\n",
      "/data/git/product-category/data/transformer_20210307C1/csv/version_0/metrics.csv\r\n",
      "/data/git/product-category/data/transformer_20210307C1/csv/version_0/hparams.yaml\r\n",
      "/data/git/product-category/data/transformer_20210307C1/tensorboard\r\n",
      "/data/git/product-category/data/transformer_20210307C1/tensorboard/version_0\r\n",
      "/data/git/product-category/data/transformer_20210307C1/tensorboard/version_0/events.out.tfevents.1615139406.ip-10-0-3-91.24318.0\r\n",
      "/data/git/product-category/data/transformer_20210307C1/tensorboard/version_0/hparams.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!find $p_out/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/git/product-category/data/transformer_20210307C1/tensorboard/\r\n",
      "/data/git/product-category/data/transformer_20210307C1/tensorboard/version_0\r\n",
      "/data/git/product-category/data/transformer_20210307C1/tensorboard/version_0/events.out.tfevents.1615139406.ip-10-0-3-91.24318.0\r\n",
      "/data/git/product-category/data/transformer_20210307C1/tensorboard/version_0/hparams.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!find $p_out/tensorboard/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!tensorboard --logdir {p_out}/tensorboard"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## save to script\n",
    "\n",
    "script = pcmodel.to_torchscript()\n",
    "# save for use in production environment\n",
    "torch.jit.save(script, f\"{p_out}/pcmodel.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pcmodel = PCModel.load_from_checkpoint(f'{p_out}/tensorboard_csv/0_0/checkpoints/epoch=9-step=1329.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/git/product-category/data/transformer_20210307C1/csv/\r\n",
      "/data/git/product-category/data/transformer_20210307C1/csv/version_0\r\n",
      "/data/git/product-category/data/transformer_20210307C1/csv/version_0/metrics.csv\r\n",
      "/data/git/product-category/data/transformer_20210307C1/csv/version_0/hparams.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!find $p_out/csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss_step</th>\n",
       "      <th>train_accu_step</th>\n",
       "      <th>gpu_id: 0/memory.used (MB)</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss_epoch</th>\n",
       "      <th>train_accu_epoch</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.552723</td>\n",
       "      <td>0.846620</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.429126</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0.521671</td>\n",
       "      <td>0.841016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2546.0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364051</td>\n",
       "      <td>0.96202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.350938</td>\n",
       "      <td>0.960778</td>\n",
       "      <td>2546.0</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.290515</td>\n",
       "      <td>0.963329</td>\n",
       "      <td>2546.0</td>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.250279</td>\n",
       "      <td>0.962372</td>\n",
       "      <td>2546.0</td>\n",
       "      <td>1</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0.298023</td>\n",
       "      <td>0.961705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.237499</td>\n",
       "      <td>0.96202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.230249</td>\n",
       "      <td>0.962054</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>2</td>\n",
       "      <td>299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.205603</td>\n",
       "      <td>0.964923</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>2</td>\n",
       "      <td>349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>2</td>\n",
       "      <td>398</td>\n",
       "      <td>0.216266</td>\n",
       "      <td>0.961705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>2</td>\n",
       "      <td>398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>0.96202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.200649</td>\n",
       "      <td>0.959503</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>3</td>\n",
       "      <td>399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.186371</td>\n",
       "      <td>0.961097</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>3</td>\n",
       "      <td>449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.160459</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>3</td>\n",
       "      <td>499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>3</td>\n",
       "      <td>531</td>\n",
       "      <td>0.182105</td>\n",
       "      <td>0.961705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>3</td>\n",
       "      <td>531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.167624</td>\n",
       "      <td>0.96202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.178298</td>\n",
       "      <td>0.959821</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>4</td>\n",
       "      <td>549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.170867</td>\n",
       "      <td>0.958227</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>4</td>\n",
       "      <td>599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.174155</td>\n",
       "      <td>0.956633</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>4</td>\n",
       "      <td>649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>4</td>\n",
       "      <td>664</td>\n",
       "      <td>0.165761</td>\n",
       "      <td>0.961705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>4</td>\n",
       "      <td>664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156816</td>\n",
       "      <td>0.96202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.169341</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>5</td>\n",
       "      <td>699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.153044</td>\n",
       "      <td>0.961416</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>5</td>\n",
       "      <td>749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>5</td>\n",
       "      <td>797</td>\n",
       "      <td>0.156981</td>\n",
       "      <td>0.961705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>5</td>\n",
       "      <td>797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.150781</td>\n",
       "      <td>0.96202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.148231</td>\n",
       "      <td>0.963010</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>6</td>\n",
       "      <td>799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.158871</td>\n",
       "      <td>0.958546</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>6</td>\n",
       "      <td>849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.154335</td>\n",
       "      <td>0.960459</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>6</td>\n",
       "      <td>899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>6</td>\n",
       "      <td>930</td>\n",
       "      <td>0.151835</td>\n",
       "      <td>0.961705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>6</td>\n",
       "      <td>930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.147108</td>\n",
       "      <td>0.96202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.149524</td>\n",
       "      <td>0.962372</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>7</td>\n",
       "      <td>949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.137702</td>\n",
       "      <td>0.965242</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>7</td>\n",
       "      <td>999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.143764</td>\n",
       "      <td>0.962691</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1063</td>\n",
       "      <td>0.148368</td>\n",
       "      <td>0.961705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144680</td>\n",
       "      <td>0.96202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.153961</td>\n",
       "      <td>0.958865</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.143309</td>\n",
       "      <td>0.962372</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1196</td>\n",
       "      <td>0.145929</td>\n",
       "      <td>0.961705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142932</td>\n",
       "      <td>0.96202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.146982</td>\n",
       "      <td>0.962054</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.161145</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.140972</td>\n",
       "      <td>0.963329</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1329</td>\n",
       "      <td>0.144175</td>\n",
       "      <td>0.961705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.141569</td>\n",
       "      <td>0.96202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss_step  train_accu_step  gpu_id: 0/memory.used (MB)  epoch  step  \\\n",
       "0          0.552723         0.846620                      2018.0      0    49   \n",
       "1          0.429126         0.957589                      2018.0      0    99   \n",
       "2               NaN              NaN                      2018.0      0   132   \n",
       "3               NaN              NaN                      2546.0      0   132   \n",
       "4          0.350938         0.960778                      2546.0      1   149   \n",
       "5          0.290515         0.963329                      2546.0      1   199   \n",
       "6          0.250279         0.962372                      2546.0      1   249   \n",
       "7               NaN              NaN                      2548.0      1   265   \n",
       "8               NaN              NaN                      2548.0      1   265   \n",
       "9          0.230249         0.962054                      2548.0      2   299   \n",
       "10         0.205603         0.964923                      2548.0      2   349   \n",
       "11              NaN              NaN                      2548.0      2   398   \n",
       "12              NaN              NaN                      2548.0      2   398   \n",
       "13         0.200649         0.959503                      2548.0      3   399   \n",
       "14         0.186371         0.961097                      2548.0      3   449   \n",
       "15         0.160459         0.969069                      2548.0      3   499   \n",
       "16              NaN              NaN                      2548.0      3   531   \n",
       "17              NaN              NaN                      2548.0      3   531   \n",
       "18         0.178298         0.959821                      2548.0      4   549   \n",
       "19         0.170867         0.958227                      2548.0      4   599   \n",
       "20         0.174155         0.956633                      2548.0      4   649   \n",
       "21              NaN              NaN                      2548.0      4   664   \n",
       "22              NaN              NaN                      2548.0      4   664   \n",
       "23         0.169341         0.957589                      2548.0      5   699   \n",
       "24         0.153044         0.961416                      2548.0      5   749   \n",
       "25              NaN              NaN                      2548.0      5   797   \n",
       "26              NaN              NaN                      2548.0      5   797   \n",
       "27         0.148231         0.963010                      2548.0      6   799   \n",
       "28         0.158871         0.958546                      2548.0      6   849   \n",
       "29         0.154335         0.960459                      2548.0      6   899   \n",
       "30              NaN              NaN                      2548.0      6   930   \n",
       "31              NaN              NaN                      2548.0      6   930   \n",
       "32         0.149524         0.962372                      2548.0      7   949   \n",
       "33         0.137702         0.965242                      2548.0      7   999   \n",
       "34         0.143764         0.962691                      2548.0      7  1049   \n",
       "35              NaN              NaN                      2548.0      7  1063   \n",
       "36              NaN              NaN                      2548.0      7  1063   \n",
       "37         0.153961         0.958865                      2548.0      8  1099   \n",
       "38         0.143309         0.962372                      2548.0      8  1149   \n",
       "39              NaN              NaN                      2548.0      8  1196   \n",
       "40              NaN              NaN                      2548.0      8  1196   \n",
       "41         0.146982         0.962054                      2548.0      9  1199   \n",
       "42         0.161145         0.955357                      2548.0      9  1249   \n",
       "43         0.140972         0.963329                      2548.0      9  1299   \n",
       "44              NaN              NaN                      2548.0      9  1329   \n",
       "45              NaN              NaN                      2548.0      9  1329   \n",
       "\n",
       "    train_loss_epoch  train_accu_epoch  valid_loss  valid_accu  \n",
       "0                NaN               NaN         NaN         NaN  \n",
       "1                NaN               NaN         NaN         NaN  \n",
       "2           0.521671          0.841016         NaN         NaN  \n",
       "3                NaN               NaN    0.364051     0.96202  \n",
       "4                NaN               NaN         NaN         NaN  \n",
       "5                NaN               NaN         NaN         NaN  \n",
       "6                NaN               NaN         NaN         NaN  \n",
       "7           0.298023          0.961705         NaN         NaN  \n",
       "8                NaN               NaN    0.237499     0.96202  \n",
       "9                NaN               NaN         NaN         NaN  \n",
       "10               NaN               NaN         NaN         NaN  \n",
       "11          0.216266          0.961705         NaN         NaN  \n",
       "12               NaN               NaN    0.189115     0.96202  \n",
       "13               NaN               NaN         NaN         NaN  \n",
       "14               NaN               NaN         NaN         NaN  \n",
       "15               NaN               NaN         NaN         NaN  \n",
       "16          0.182105          0.961705         NaN         NaN  \n",
       "17               NaN               NaN    0.167624     0.96202  \n",
       "18               NaN               NaN         NaN         NaN  \n",
       "19               NaN               NaN         NaN         NaN  \n",
       "20               NaN               NaN         NaN         NaN  \n",
       "21          0.165761          0.961705         NaN         NaN  \n",
       "22               NaN               NaN    0.156816     0.96202  \n",
       "23               NaN               NaN         NaN         NaN  \n",
       "24               NaN               NaN         NaN         NaN  \n",
       "25          0.156981          0.961705         NaN         NaN  \n",
       "26               NaN               NaN    0.150781     0.96202  \n",
       "27               NaN               NaN         NaN         NaN  \n",
       "28               NaN               NaN         NaN         NaN  \n",
       "29               NaN               NaN         NaN         NaN  \n",
       "30          0.151835          0.961705         NaN         NaN  \n",
       "31               NaN               NaN    0.147108     0.96202  \n",
       "32               NaN               NaN         NaN         NaN  \n",
       "33               NaN               NaN         NaN         NaN  \n",
       "34               NaN               NaN         NaN         NaN  \n",
       "35          0.148368          0.961705         NaN         NaN  \n",
       "36               NaN               NaN    0.144680     0.96202  \n",
       "37               NaN               NaN         NaN         NaN  \n",
       "38               NaN               NaN         NaN         NaN  \n",
       "39          0.145929          0.961705         NaN         NaN  \n",
       "40               NaN               NaN    0.142932     0.96202  \n",
       "41               NaN               NaN         NaN         NaN  \n",
       "42               NaN               NaN         NaN         NaN  \n",
       "43               NaN               NaN         NaN         NaN  \n",
       "44          0.144175          0.961705         NaN         NaN  \n",
       "45               NaN               NaN    0.141569     0.96202  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmtr = pd.read_csv(f\"{p_out}/csv/version_0/metrics.csv\")\n",
    "\n",
    "dfmtr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dl = data_module.val_dataloader()\n",
    "n=0\n",
    "for dat in dl:\n",
    "    input_ids, attention_mask, ys = dat\n",
    "    logits = pcmodel(input_ids, attention_mask)\n",
    "    accu = getaccu(logits, ys)\n",
    "    print(accu.item())\n",
    "    n+=1\n",
    "    if n>1: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_demo(df):\n",
    "    i2cat = data_module.i2cat\n",
    "    tokenizer = data_module.tokenizer\n",
    "    max_seq_length = data_module.max_seq_length\n",
    "    row = df.sample()\n",
    "    display(row)\n",
    "    txt = list(row.title.values)\n",
    "    input_ids, attention_mask = mk_tensors(txt, tokenizer, max_seq_length)\n",
    "    logits = pcmodel(input_ids, attention_mask)[0]\n",
    "    print('Truth:', sorted(o for o in row.category.values[0].split('|') if o in i2cat))\n",
    "\n",
    "    top_icats = np.argsort(-logits.detach().numpy())[:5]\n",
    "    print('Top Preds:',[i2cat[i] for i in top_icats])\n",
    "    print('Preds 0.5+:',[i2cat[i] for i in np.where(logits>0)[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>is_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4913</th>\n",
       "      <td>Books|Literature &amp;amp; Fiction|Genre Fiction</td>\n",
       "      <td>My Interview with Beethoven</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          category  \\\n",
       "4913  Books|Literature &amp; Fiction|Genre Fiction   \n",
       "\n",
       "                            title  is_validation  \n",
       "4913  My Interview with Beethoven              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: ['Books', 'Literature &amp; Fiction']\n",
      "Top Preds: ['Books', 'Clothing, Shoes & Jewelry', 'Women', 'Clothing', 'Home & Kitchen']\n",
      "Preds 0.5+: []\n"
     ]
    }
   ],
   "source": [
    "do_demo(data_module.df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar  7 17:54:39 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   53C    P0    44W / 300W |   1252MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     24318      C   ...conda3/envs/product-category/bin/python  1241MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "product-category",
   "language": "python",
   "name": "product-category"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
