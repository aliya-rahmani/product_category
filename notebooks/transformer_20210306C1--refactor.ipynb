{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  6 19:44:31 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   55C    P0    45W / 300W |      0MiB / 16160MiB |      4%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=goRmGIRI5cfC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:8080/notebooks/git/product-category/notebooks/prep_20210304A1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prfx_prp = 'prep_20210304A1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = \"/data/git/product-category\"\n",
    "p_out = f'{HOME}/data/transformer_20210306C1'\n",
    "!mkdir -p {p_out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = int(1e5)\n",
    "DATA2USE = f'{HOME}/data/data_sample_{sz}__{prfx_prp}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9)\n",
      "CPU times: user 16.5 ms, sys: 4.11 ms, total: 20.6 ms\n",
      "Wall time: 19.3 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>asin</th>\n",
       "      <th>domain</th>\n",
       "      <th>txt</th>\n",
       "      <th>is_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Kindle Store|Kindle eBooks|Romance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cyclone: A Psychic Romance Suspense (An Elemen...</td>\n",
       "      <td>Visit Amazon's Larissa Ladd Page</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00PKP7YEU</td>\n",
       "      <td>Kindle_Store</td>\n",
       "      <td>Cyclone: A Psychic Romance Suspense (An Elemen...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Books|Literature &amp;amp; Fiction|Humor &amp;amp; Satire</td>\n",
       "      <td>\\n\\n\\n\\n\\n</td>\n",
       "      <td>The Cat Who Wasn't a Dog</td>\n",
       "      <td>Visit Amazon's Marian Babson Page</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0312991371</td>\n",
       "      <td>Book</td>\n",
       "      <td>The Cat Who Wasn't a Dog Visit Amazon's Marian...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Kindle Store|Kindle eBooks|Science Fiction &amp; F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After Invasion eBook</td>\n",
       "      <td>Keith Luethke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B009BHMDIU</td>\n",
       "      <td>Kindle_Store</td>\n",
       "      <td>After Invasion eBook Keith Luethke</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              category description  \\\n",
       "234                 Kindle Store|Kindle eBooks|Romance         NaN   \n",
       "12   Books|Literature &amp; Fiction|Humor &amp; Satire  \\n\\n\\n\\n\\n   \n",
       "661  Kindle Store|Kindle eBooks|Science Fiction & F...         NaN   \n",
       "\n",
       "                                                 title  \\\n",
       "234  Cyclone: A Psychic Romance Suspense (An Elemen...   \n",
       "12                            The Cat Who Wasn't a Dog   \n",
       "661                               After Invasion eBook   \n",
       "\n",
       "                                 brand feature        asin        domain  \\\n",
       "234   Visit Amazon's Larissa Ladd Page     NaN  B00PKP7YEU  Kindle_Store   \n",
       "12   Visit Amazon's Marian Babson Page     NaN  0312991371          Book   \n",
       "661                      Keith Luethke     NaN  B009BHMDIU  Kindle_Store   \n",
       "\n",
       "                                                   txt  is_validation  \n",
       "234  Cyclone: A Psychic Romance Suspense (An Elemen...            0.0  \n",
       "12   The Cat Who Wasn't a Dog Visit Amazon's Marian...            0.0  \n",
       "661               After Invasion eBook Keith Luethke              0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# df = pd.read_csv(f'../data/data__{prfx_prp}.csv')\n",
    "# df = pd.read_csv(f'{HOME}/data/data_sample__{prfx_prp}.csv')\n",
    "df = pd.read_csv(DATA2USE, nrows=1000)\n",
    "print(df.shape)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.924"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.txt.notna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(i2dmn), len(i2cat) 22 8\n",
      "Arts_Crafts_and_Sewi|Automotive|Book|CDs_and_Vinyl|Cell_Phones_and_Accessorie|Clothing_Shoes_and_Jewelry|Electronic|Grocery_and_Gourmet_Food|Home_and_Kitche|Industrial_and_Scientific|Kindle_Store|Magazine_Subscripti|Movies_and_TV|Musical_Instrument|Office_Product|Patio_Lawn_and_Garde|Pet_Supplie|Software|Sports_and_Outdoor|Tools_and_Home_Improvement|Toys_and_Game|Video_Game\n",
      "\n",
      "Automotive|Books|Clothing|Clothing, Shoes & Jewelry|Home & Kitchen|Men|Sports & Outdoors|Women\n"
     ]
    }
   ],
   "source": [
    "MIN_CNT = 50\n",
    "dmn2cnt = Counter(df.domain.value_counts().to_dict())\n",
    "i2dmn = sorted(dmn2cnt.keys())\n",
    "dmn2i = {v:k for k,v in enumerate(i2dmn)}\n",
    "cat2cnt = Counter((j for i in df.category.apply(lambda x: x.split('|')) for j in i))\n",
    "i2cat = sorted(k for k,v in cat2cnt.items() if v>50)\n",
    "cat2i = {v:k for k,v in enumerate(i2cat)}\n",
    "\n",
    "print(\"len(i2dmn), len(i2cat)\", len(i2dmn), len(i2cat))\n",
    "print(\"|\".join(i2dmn))\n",
    "print()\n",
    "print(\"|\".join(i2cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import pytorch_lightning as pl\n",
    "from transformers.optimization import AdamW\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "def mk_tensors(txt, tokenizer, max_seq_length):\n",
    "    tok_res = tokenizer(\n",
    "        txt, truncation=True, padding='max_length', max_length=max_seq_length\n",
    "    )\n",
    "    input_ids = tok_res[\"input_ids\"]\n",
    "    attention_mask = tok_res[\"attention_mask\"]\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    return input_ids, attention_mask\n",
    "\n",
    "def mk_ds(txt, tokenizer, max_seq_length, ys):\n",
    "    input_ids, attention_mask = mk_tensors(txt, tokenizer, max_seq_length)\n",
    "    return TensorDataset(input_ids, \n",
    "                         attention_mask, \n",
    "                         torch.tensor(ys)) \n",
    "\n",
    "class PCDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 model_name_or_path, \n",
    "                 max_seq_length, \n",
    "                 min_products_for_category,\n",
    "                 train_batch_size,\n",
    "                 val_batch_size,\n",
    "                 dataloader_num_workers,\n",
    "                 data_file_path=None,\n",
    "                 dataframe=None):\n",
    "        super().__init__()\n",
    "        self.data_file_path = data_file_path\n",
    "        self.dataframe = dataframe\n",
    "        self.min_products_for_category = min_products_for_category\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.val_batch_size = val_batch_size\n",
    "        self.dataloader_num_workers = dataloader_num_workers\n",
    "        self.num_classes = None\n",
    "      \n",
    "    def prepare_data(self):\n",
    "        #prepare_data is called from a single process (e.g. GPU 0). Do not use it to assign state (self.x = y).\n",
    "        _ = AutoTokenizer.from_pretrained(self.model_name_or_path)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path)\n",
    "        if self.dataframe is None:\n",
    "            self.dataframe = pd.read_csv(self.data_file_path)\n",
    "        \n",
    "        self.dataframe = self.dataframe[self.dataframe.txt.notna()].copy()\n",
    "        \n",
    "        cats = self.dataframe.category.apply(lambda x: x.split('|'))\n",
    "        cat2cnt = Counter((j for i in cats for j in i))\n",
    "        i2cat = sorted(k for k,v in cat2cnt.items() if v>self.min_products_for_category)\n",
    "        cat2i = {v:k for k,v in enumerate(i2cat)}\n",
    "        self.num_classes = len(i2cat)\n",
    "        self.i2cat, self.cat2i = i2cat, cat2i\n",
    "        \n",
    "        ys = np.zeros((len(self.dataframe), len(i2cat)))\n",
    "        for i,cats in enumerate(self.dataframe.category):\n",
    "            idx_pos = [cat2i[cat] for cat in cats.split('|') if cat in cat2i]\n",
    "            ys[i,idx_pos] = 1\n",
    "        \n",
    "        msk_val = self.dataframe.is_validation==1\n",
    "        self.df_trn = self.dataframe[~msk_val]\n",
    "        self.df_val = self.dataframe[msk_val]\n",
    "        idx_trn = np.where(~msk_val)[0]\n",
    "        idx_val = np.where(msk_val)[0]\n",
    "        self.ys_trn, self.ys_val = ys[idx_trn], ys[idx_val]\n",
    "        \n",
    "        txt = self.dataframe.txt.values\n",
    "        self.train_dataset = mk_ds(list(self.df_trn.txt), self.tokenizer, self.max_seq_length, self.ys_trn)\n",
    "        self.eval_dataset  = mk_ds(list(self.df_val.txt), self.tokenizer, self.max_seq_length, self.ys_val)\n",
    "        \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.train_batch_size,\n",
    "            num_workers=self.dataloader_num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.eval_dataset,\n",
    "            batch_size=self.val_batch_size,\n",
    "            num_workers=self.dataloader_num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "def getaccu(logits, ys):\n",
    "    return ((logits>0.).int() == ys).float().mean()\n",
    "\n",
    "class PCModel(pl.LightningModule):\n",
    "    def __init__(self, model_name_or_path, num_classes, learning_rate, adam_beta1, adam_beta2, adam_epsilon):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.bert = AutoModel.from_pretrained(self.model_name_or_path)\n",
    "        self.num_classes = num_classes\n",
    "        self.W = nn.Linear(self.bert.config.hidden_size, self.num_classes)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        #prepare_data is called from a single process (e.g. GPU 0). Do not use it to assign state (self.x = y).\n",
    "        _ = AutoModel.from_pretrained(self.model_name_or_path)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        h = self.bert(input_ids, attention_mask)['last_hidden_state']\n",
    "        h_cls = h[:, 0]\n",
    "        return self.W(h_cls)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, ys = batch    \n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, ys)\n",
    "        accu = getaccu(logits, ys)\n",
    "        self.log('train_loss', loss, on_epoch=True)\n",
    "        self.log('train_accu', accu, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, ys = batch    \n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, ys)\n",
    "        accu = getaccu(logits, ys)\n",
    "        self.log('valid_loss', loss, on_step=False, sync_dist=True)\n",
    "        self.log('valid_accu', accu, on_step=False, sync_dist=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(),\n",
    "                          self.hparams.learning_rate,\n",
    "                          betas=(self.hparams.adam_beta1,\n",
    "                                 self.hparams.adam_beta2),\n",
    "                          eps=self.hparams.adam_epsilon,)\n",
    "        return optimizer    \n",
    "    \n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument('--learning_rate', type=float, default=5e-5)\n",
    "        parser.add_argument('--adam_beta1', type=float, default=0.9)\n",
    "        parser.add_argument('--adam_beta2', type=float, default=0.999)\n",
    "        parser.add_argument('--adam_epsilon', type=float, default=1e-8)\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "\n",
    "parser.add_argument('--model_name_or_path', type=str,\n",
    "                    default=\"distilbert-base-cased\")\n",
    "parser.add_argument('--max_seq_length', type=int, default=512)\n",
    "parser.add_argument('--min_products_for_category', type=int, default=100)\n",
    "parser.add_argument('--train_batch_size', type=int, default=32)\n",
    "parser.add_argument('--val_batch_size', type=int, default=64)\n",
    "parser.add_argument(\"--dataloader_num_workers\", type=int, default=8)\n",
    "\n",
    "parser = pl.Trainer.add_argparse_args(parser)\n",
    "parser = PCModel.add_model_specific_args(parser)\n",
    "\n",
    "args = parser.parse_args([\n",
    "    '--default_root_dir', p_out,\n",
    "])\n",
    "\n",
    "\n",
    "data_module = PCDataModule(\n",
    "    model_name_or_path=args.model_name_or_path,\n",
    "#     data_file_path=f'{HOME}/data/data_sample__{prfx_prp}.csv',\n",
    "    data_file_path=DATA2USE,\n",
    "    min_products_for_category=args.min_products_for_category,\n",
    "    max_seq_length=args.max_seq_length,\n",
    "    train_batch_size=args.train_batch_size,\n",
    "    val_batch_size=args.val_batch_size,\n",
    "    dataloader_num_workers=args.dataloader_num_workers,\n",
    ")\n",
    "\n",
    "data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 4.97 s, total: 1min 31s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmodel = PCModel(\n",
    "    model_name_or_path=args.model_name_or_path,\n",
    "    num_classes= data_module.num_classes,\n",
    "    learning_rate=args.learning_rate,\n",
    "    adam_beta1=args.adam_beta1,\n",
    "    adam_beta2=args.adam_beta2,\n",
    "    adam_epsilon=args.adam_epsilon,\n",
    ")\n",
    "pcmodel.prepare_data()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dl = data_module.val_dataloader()\n",
    "n=0\n",
    "for dat in dl:\n",
    "    input_ids, attention_mask, ys = dat\n",
    "    logits = pcmodel(input_ids, attention_mask)\n",
    "    accu = getaccu(logits, ys)\n",
    "    print(accu.item())\n",
    "    n+=1\n",
    "    if n>1: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "\n",
    "pl.seed_everything(1234)\n",
    "trainer = pl.Trainer.from_argparse_args(args, \n",
    "#                                         limit_train_batches=10, limit_val_batches=5, \n",
    "                                        max_epochs=10,\n",
    "                                        callbacks=[EarlyStopping(monitor='valid_loss')],\n",
    "#                                         fast_dev_run=True,\n",
    "                                        stochastic_weight_avg=True,\n",
    "                                        log_gpu_memory=True, \n",
    "                                        gpus=1,\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type            | Params\n",
      "-----------------------------------------\n",
      "0 | bert | DistilBertModel | 65.2 M\n",
      "1 | W    | Linear          | 376 K \n",
      "-----------------------------------------\n",
      "65.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "65.6 M    Total params\n",
      "262.271   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/product-category/lib/python3.7/site-packages/pytorch_lightning/core/step_result.py:148: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  value = torch.tensor(value, device=device, dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4cf1db4c7d040cd9f37712182fdea71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(pcmodel, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_0  version_1\r\n"
     ]
    }
   ],
   "source": [
    "!ls {p_out}/lightning_logs/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!tensorboard --logdir {p_out}/lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/git/product-category/data/transformer_20210306C1/lightning_logs/version_0/checkpoints/:\r\n",
      "total 747M\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 747M Mar  6 19:37 'epoch=6-step=1749.ckpt'\r\n",
      "\r\n",
      "/data/git/product-category/data/transformer_20210306C1/lightning_logs/version_1/checkpoints/:\r\n",
      "total 751M\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 751M Mar  6 22:13 'epoch=6-step=17317.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "ls -hl $p_out/lightning_logs/version_*/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmodel = PCModel.load_from_checkpoint(f'{p_out}/lightning_logs/version_1/checkpoints/epoch=6-step=17317.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dl = data_module.val_dataloader()\n",
    "n=0\n",
    "for dat in dl:\n",
    "    input_ids, attention_mask, ys = dat\n",
    "    logits = pcmodel(input_ids, attention_mask)\n",
    "    accu = getaccu(logits, ys)\n",
    "    print(accu.item())\n",
    "    n+=1\n",
    "    if n>1: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcheckpoints\u001b[0m/  events.out.tfevents.1615059909.ip-10-0-3-91.12209.0  hparams.yaml\r\n"
     ]
    }
   ],
   "source": [
    "ls $p_out/lightning_logs/version_1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_demo(df):\n",
    "    i2cat = data_module.i2cat\n",
    "    tokenizer = data_module.tokenizer\n",
    "    max_seq_length = data_module.max_seq_length\n",
    "    row = df.sample()\n",
    "    display(row)\n",
    "    txt = list(row.txt.values)\n",
    "    input_ids, attention_mask = mk_tensors(txt, tokenizer, max_seq_length)\n",
    "    logits = pcmodel(input_ids, attention_mask)[0]\n",
    "    print('Truth:', sorted(o for o in row.category.values[0].split('|') if o in i2cat))\n",
    "\n",
    "    top_icats = np.argsort(-logits.detach().numpy())[:5]\n",
    "    print('Top Preds:',[i2cat[i] for i in top_icats])\n",
    "    print('Preds 0.5+:',[i2cat[i] for i in np.where(logits>0)[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>asin</th>\n",
       "      <th>domain</th>\n",
       "      <th>txt</th>\n",
       "      <th>is_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68562</th>\n",
       "      <td>Books|Children's Books|Animals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Happy: The Cavalier King Charles Spaniel</td>\n",
       "      <td>Kathleen Mary Clancy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1946300071</td>\n",
       "      <td>Book</td>\n",
       "      <td>Happy: The Cavalier King Charles Spaniel Kathl...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             category description  \\\n",
       "68562  Books|Children's Books|Animals         NaN   \n",
       "\n",
       "                                          title                 brand feature  \\\n",
       "68562  Happy: The Cavalier King Charles Spaniel  Kathleen Mary Clancy     NaN   \n",
       "\n",
       "             asin domain                                                txt  \\\n",
       "68562  1946300071   Book  Happy: The Cavalier King Charles Spaniel Kathl...   \n",
       "\n",
       "       is_validation  \n",
       "68562            1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: ['Animals', 'Books', \"Children's Books\"]\n",
      "Top Preds: ['Books', 'Literature &amp; Fiction', 'Literature & Fiction', 'Contemporary', 'Action &amp; Adventure']\n",
      "Preds 0.5+: ['Books']\n"
     ]
    }
   ],
   "source": [
    "do_demo(data_module.df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save to script"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "script = pcmodel.to_torchscript()\n",
    "# save for use in production environment\n",
    "torch.jit.save(script, f\"{p_out}/pcmodel.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  6 22:13:38 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   62C    P0    60W / 300W |   1972MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     12209      C   ...conda3/envs/product-category/bin/python  1961MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "product-category",
   "language": "python",
   "name": "product-category"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
