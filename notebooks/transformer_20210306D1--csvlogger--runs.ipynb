{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar  7 01:54:37 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   43C    P0    40W / 300W |      0MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=goRmGIRI5cfC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://localhost:8080/notebooks/git/product-category/notebooks/prep_20210304A1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prfx_prp = 'prep_20210304A1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = \"/data/git/product-category\"\n",
    "p_out = f'{HOME}/data/transformer_20210306D1'\n",
    "!mkdir -p {p_out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = int(1e4)\n",
    "DATA2USE = f'{HOME}/data/data_sample_{sz}__{prfx_prp}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9)\n",
      "CPU times: user 21.6 ms, sys: 54 Âµs, total: 21.7 ms\n",
      "Wall time: 27.6 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>asin</th>\n",
       "      <th>domain</th>\n",
       "      <th>txt</th>\n",
       "      <th>is_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Home &amp; Kitchen|Home Dcor|Home Dcor Accents|Orn...</td>\n",
       "      <td>This Round Sand Picture features a wavy design...</td>\n",
       "      <td>G.W. Schleidt SSR BW 6 in. Round Sand Picture ...</td>\n",
       "      <td>G W Schleidt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00DQB5O1K</td>\n",
       "      <td>Home_and_Kitche</td>\n",
       "      <td>G.W. Schleidt SSR BW 6 in. Round Sand Picture ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>CDs &amp; Vinyl|Classical|Forms &amp; Genres|Sonatas</td>\n",
       "      <td>Evgeny Kissin has made brave choices in select...</td>\n",
       "      <td>Schumann: Carnaval Op. 9 / Sonata No. 1 in F S...</td>\n",
       "      <td>Evgeny Kissin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B0000665WU</td>\n",
       "      <td>CDs_and_Vinyl</td>\n",
       "      <td>Schumann: Carnaval Op. 9 / Sonata No. 1 in F S...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Automotive|Replacement Parts|Fuel System|Carbu...</td>\n",
       "      <td>Carburetor W/ Gasket Tecumseh 640338 640274 Carb</td>\n",
       "      <td>Carburetor W/ Gasket Tecumseh 640338 640274 Carb</td>\n",
       "      <td>KING</td>\n",
       "      <td>Free domestic shipping\\nOne Year Warranty\\nBra...</td>\n",
       "      <td>B00LKEJT0C</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Carburetor W/ Gasket Tecumseh 640338 640274 Ca...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              category  \\\n",
       "408  Home & Kitchen|Home Dcor|Home Dcor Accents|Orn...   \n",
       "169       CDs & Vinyl|Classical|Forms & Genres|Sonatas   \n",
       "355  Automotive|Replacement Parts|Fuel System|Carbu...   \n",
       "\n",
       "                                           description  \\\n",
       "408  This Round Sand Picture features a wavy design...   \n",
       "169  Evgeny Kissin has made brave choices in select...   \n",
       "355   Carburetor W/ Gasket Tecumseh 640338 640274 Carb   \n",
       "\n",
       "                                                 title          brand  \\\n",
       "408  G.W. Schleidt SSR BW 6 in. Round Sand Picture ...   G W Schleidt   \n",
       "169  Schumann: Carnaval Op. 9 / Sonata No. 1 in F S...  Evgeny Kissin   \n",
       "355   Carburetor W/ Gasket Tecumseh 640338 640274 Carb           KING   \n",
       "\n",
       "                                               feature        asin  \\\n",
       "408                                                NaN  B00DQB5O1K   \n",
       "169                                                NaN  B0000665WU   \n",
       "355  Free domestic shipping\\nOne Year Warranty\\nBra...  B00LKEJT0C   \n",
       "\n",
       "              domain                                                txt  \\\n",
       "408  Home_and_Kitche  G.W. Schleidt SSR BW 6 in. Round Sand Picture ...   \n",
       "169    CDs_and_Vinyl  Schumann: Carnaval Op. 9 / Sonata No. 1 in F S...   \n",
       "355       Automotive  Carburetor W/ Gasket Tecumseh 640338 640274 Ca...   \n",
       "\n",
       "     is_validation  \n",
       "408            0.0  \n",
       "169            0.0  \n",
       "355            0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# df = pd.read_csv(f'../data/data__{prfx_prp}.csv')\n",
    "# df = pd.read_csv(f'{HOME}/data/data_sample__{prfx_prp}.csv')\n",
    "df = pd.read_csv(DATA2USE, nrows=1000)\n",
    "print(df.shape)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.938"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.txt.notna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(i2dmn), len(i2cat) 22 9\n",
      "Appliance|Arts_Crafts_and_Sewi|Automotive|Book|CDs_and_Vinyl|Cell_Phones_and_Accessorie|Clothing_Shoes_and_Jewelry|Electronic|Grocery_and_Gourmet_Food|Home_and_Kitche|Industrial_and_Scientific|Kindle_Store|Movies_and_TV|Musical_Instrument|Office_Product|Patio_Lawn_and_Garde|Pet_Supplie|Software|Sports_and_Outdoor|Tools_and_Home_Improvement|Toys_and_Game|Video_Game\n",
      "\n",
      "Automotive|Books|Clothing|Clothing, Shoes & Jewelry|Electronics|Home & Kitchen|Men|Sports & Outdoors|Women\n"
     ]
    }
   ],
   "source": [
    "MIN_CNT = 50\n",
    "dmn2cnt = Counter(df.domain.value_counts().to_dict())\n",
    "i2dmn = sorted(dmn2cnt.keys())\n",
    "dmn2i = {v:k for k,v in enumerate(i2dmn)}\n",
    "cat2cnt = Counter((j for i in df.category.apply(lambda x: x.split('|')) for j in i))\n",
    "i2cat = sorted(k for k,v in cat2cnt.items() if v>50)\n",
    "cat2i = {v:k for k,v in enumerate(i2cat)}\n",
    "\n",
    "print(\"len(i2dmn), len(i2cat)\", len(i2dmn), len(i2cat))\n",
    "print(\"|\".join(i2dmn))\n",
    "print()\n",
    "print(\"|\".join(i2cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import pytorch_lightning as pl\n",
    "from transformers.optimization import AdamW\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "def mk_tensors(txt, tokenizer, max_seq_length):\n",
    "    tok_res = tokenizer(\n",
    "        txt, truncation=True, padding='max_length', max_length=max_seq_length\n",
    "    )\n",
    "    input_ids = tok_res[\"input_ids\"]\n",
    "    attention_mask = tok_res[\"attention_mask\"]\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    return input_ids, attention_mask\n",
    "\n",
    "def mk_ds(txt, tokenizer, max_seq_length, ys):\n",
    "    input_ids, attention_mask = mk_tensors(txt, tokenizer, max_seq_length)\n",
    "    return TensorDataset(input_ids, \n",
    "                         attention_mask, \n",
    "                         torch.tensor(ys)) \n",
    "\n",
    "class PCDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 model_name_or_path, \n",
    "                 max_seq_length, \n",
    "                 min_products_for_category,\n",
    "                 train_batch_size,\n",
    "                 val_batch_size,\n",
    "                 dataloader_num_workers,\n",
    "                 data_file_path=None,\n",
    "                 dataframe=None):\n",
    "        super().__init__()\n",
    "        self.data_file_path = data_file_path\n",
    "        self.dataframe = dataframe\n",
    "        self.min_products_for_category = min_products_for_category\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.val_batch_size = val_batch_size\n",
    "        self.dataloader_num_workers = dataloader_num_workers\n",
    "        self.num_classes = None\n",
    "      \n",
    "    def prepare_data(self):\n",
    "        #prepare_data is called from a single process (e.g. GPU 0). Do not use it to assign state (self.x = y).\n",
    "        _ = AutoTokenizer.from_pretrained(self.model_name_or_path)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path)\n",
    "        if self.dataframe is None:\n",
    "            self.dataframe = pd.read_csv(self.data_file_path)\n",
    "        \n",
    "        self.dataframe = self.dataframe[self.dataframe.txt.notna()].copy()\n",
    "        \n",
    "        cats = self.dataframe.category.apply(lambda x: x.split('|'))\n",
    "        cat2cnt = Counter((j for i in cats for j in i))\n",
    "        i2cat = sorted(k for k,v in cat2cnt.items() if v>self.min_products_for_category)\n",
    "        cat2i = {v:k for k,v in enumerate(i2cat)}\n",
    "        self.num_classes = len(i2cat)\n",
    "        self.i2cat, self.cat2i = i2cat, cat2i\n",
    "        \n",
    "        ys = np.zeros((len(self.dataframe), len(i2cat)))\n",
    "        for i,cats in enumerate(self.dataframe.category):\n",
    "            idx_pos = [cat2i[cat] for cat in cats.split('|') if cat in cat2i]\n",
    "            ys[i,idx_pos] = 1\n",
    "        \n",
    "        msk_val = self.dataframe.is_validation==1\n",
    "        self.df_trn = self.dataframe[~msk_val]\n",
    "        self.df_val = self.dataframe[msk_val]\n",
    "        idx_trn = np.where(~msk_val)[0]\n",
    "        idx_val = np.where(msk_val)[0]\n",
    "        self.ys_trn, self.ys_val = ys[idx_trn], ys[idx_val]\n",
    "        \n",
    "        txt = self.dataframe.txt.values\n",
    "        self.train_dataset = mk_ds(list(self.df_trn.txt), self.tokenizer, self.max_seq_length, self.ys_trn)\n",
    "        self.eval_dataset  = mk_ds(list(self.df_val.txt), self.tokenizer, self.max_seq_length, self.ys_val)\n",
    "        \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.train_batch_size,\n",
    "            num_workers=self.dataloader_num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.eval_dataset,\n",
    "            batch_size=self.val_batch_size,\n",
    "            num_workers=self.dataloader_num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "def getaccu(logits, ys):\n",
    "    return ((logits>0.).int() == ys).float().mean()\n",
    "\n",
    "class PCModel(pl.LightningModule):\n",
    "    def __init__(self, model_name_or_path, num_classes, learning_rate, adam_beta1, adam_beta2, adam_epsilon):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.bert = AutoModel.from_pretrained(self.model_name_or_path)\n",
    "        self.num_classes = num_classes\n",
    "        self.W = nn.Linear(self.bert.config.hidden_size, self.num_classes)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        #prepare_data is called from a single process (e.g. GPU 0). Do not use it to assign state (self.x = y).\n",
    "        _ = AutoModel.from_pretrained(self.model_name_or_path)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        h = self.bert(input_ids, attention_mask)['last_hidden_state']\n",
    "        h_cls = h[:, 0]\n",
    "        return self.W(h_cls)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, ys = batch    \n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, ys)\n",
    "        accu = getaccu(logits, ys)\n",
    "        self.log('train_loss', loss, on_epoch=True)\n",
    "        self.log('train_accu', accu, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, ys = batch    \n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, ys)\n",
    "        accu = getaccu(logits, ys)\n",
    "        self.log('valid_loss', loss, on_step=False, sync_dist=True)\n",
    "        self.log('valid_accu', accu, on_step=False, sync_dist=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(),\n",
    "                          self.hparams.learning_rate,\n",
    "                          betas=(self.hparams.adam_beta1,\n",
    "                                 self.hparams.adam_beta2),\n",
    "                          eps=self.hparams.adam_epsilon,)\n",
    "        return optimizer    \n",
    "    \n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument('--learning_rate', type=float, default=5e-5)\n",
    "        parser.add_argument('--adam_beta1', type=float, default=0.9)\n",
    "        parser.add_argument('--adam_beta2', type=float, default=0.999)\n",
    "        parser.add_argument('--adam_epsilon', type=float, default=1e-8)\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "\n",
    "parser.add_argument('--model_name_or_path', type=str,\n",
    "                    default=\"distilbert-base-cased\")\n",
    "parser.add_argument('--max_seq_length', type=int, default=512)\n",
    "parser.add_argument('--min_products_for_category', type=int, default=100)\n",
    "parser.add_argument('--train_batch_size', type=int, default=32)\n",
    "parser.add_argument('--val_batch_size', type=int, default=64)\n",
    "parser.add_argument(\"--dataloader_num_workers\", type=int, default=8)\n",
    "\n",
    "parser = pl.Trainer.add_argparse_args(parser)\n",
    "parser = PCModel.add_model_specific_args(parser)\n",
    "\n",
    "args = parser.parse_args([\n",
    "    '--default_root_dir', p_out,\n",
    "])\n",
    "\n",
    "\n",
    "data_module = PCDataModule(\n",
    "    model_name_or_path=args.model_name_or_path,\n",
    "#     data_file_path=f'{HOME}/data/data_sample__{prfx_prp}.csv',\n",
    "    data_file_path=DATA2USE,\n",
    "    min_products_for_category=args.min_products_for_category,\n",
    "    max_seq_length=args.max_seq_length,\n",
    "    train_batch_size=args.train_batch_size,\n",
    "    val_batch_size=args.val_batch_size,\n",
    "    dataloader_num_workers=args.dataloader_num_workers,\n",
    ")\n",
    "\n",
    "data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.86 s, sys: 450 ms, total: 9.31 s\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcmodel = PCModel(\n",
    "    model_name_or_path=args.model_name_or_path,\n",
    "    num_classes= data_module.num_classes,\n",
    "    learning_rate=args.learning_rate,\n",
    "    adam_beta1=args.adam_beta1,\n",
    "    adam_beta2=args.adam_beta2,\n",
    "    adam_epsilon=args.adam_epsilon,\n",
    ")\n",
    "pcmodel.prepare_data()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dl = data_module.val_dataloader()\n",
    "n=0\n",
    "for dat in dl:\n",
    "    input_ids, attention_mask, ys = dat\n",
    "    logits = pcmodel(input_ids, attention_mask)\n",
    "    accu = getaccu(logits, ys)\n",
    "    print(accu.item())\n",
    "    n+=1\n",
    "    if n>1: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger(p_out, name='csv')\n",
    "tb_logger = TensorBoardLogger(p_out, name='tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(1234)\n",
    "trainer = pl.Trainer.from_argparse_args(args, \n",
    "#                                         limit_train_batches=10, limit_val_batches=5, \n",
    "                                        max_epochs=1,\n",
    "                                        callbacks=[EarlyStopping(monitor='valid_loss')],\n",
    "#                                         fast_dev_run=True,\n",
    "                                        stochastic_weight_avg=True,\n",
    "                                        log_gpu_memory=True, \n",
    "                                        gpus=1,\n",
    "                                        logger=[tb_logger,csv_logger],\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type            | Params\n",
      "-----------------------------------------\n",
      "0 | bert | DistilBertModel | 65.2 M\n",
      "1 | W    | Linear          | 37.7 K\n",
      "-----------------------------------------\n",
      "65.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "65.2 M    Total params\n",
      "260.914   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layoutâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3d71a112a24062ad16f3f0ef48440f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), maxâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), mâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(pcmodel, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.out.tfevents.1615082428.ip-10-0-3-91.31684.1  hparams.yaml\r\n"
     ]
    }
   ],
   "source": [
    "ls $p_out/tensorboard/version_0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!tensorboard --logdir {p_out}/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/git/product-category/data/transformer_20210306D1/\r\n",
      "/data/git/product-category/data/transformer_20210306D1/default\r\n",
      "/data/git/product-category/data/transformer_20210306D1/default/version_1\r\n",
      "/data/git/product-category/data/transformer_20210306D1/default/version_1/metrics.csv\r\n",
      "/data/git/product-category/data/transformer_20210306D1/default/version_1/hparams.yaml\r\n",
      "/data/git/product-category/data/transformer_20210306D1/default/version_0\r\n",
      "/data/git/product-category/data/transformer_20210306D1/default/version_0/hparams.yaml\r\n",
      "/data/git/product-category/data/transformer_20210306D1/default/version_0/events.out.tfevents.1615082268.ip-10-0-3-91.31684.0\r\n",
      "/data/git/product-category/data/transformer_20210306D1/tensorboard_csv\r\n",
      "/data/git/product-category/data/transformer_20210306D1/tensorboard_csv/0_0\r\n",
      "/data/git/product-category/data/transformer_20210306D1/tensorboard_csv/0_0/checkpoints\r\n",
      "/data/git/product-category/data/transformer_20210306D1/tensorboard_csv/0_0/checkpoints/epoch=0-step=249.ckpt\r\n",
      "/data/git/product-category/data/transformer_20210306D1/tensorboard_csv/.ipynb_checkpoints\r\n",
      "/data/git/product-category/data/transformer_20210306D1/default_default\r\n",
      "/data/git/product-category/data/transformer_20210306D1/default_default/.ipynb_checkpoints\r\n",
      "/data/git/product-category/data/transformer_20210306D1/csv\r\n",
      "/data/git/product-category/data/transformer_20210306D1/csv/version_0\r\n",
      "/data/git/product-category/data/transformer_20210306D1/csv/version_0/metrics.csv\r\n",
      "/data/git/product-category/data/transformer_20210306D1/csv/version_0/hparams.yaml\r\n",
      "/data/git/product-category/data/transformer_20210306D1/tensorboard\r\n",
      "/data/git/product-category/data/transformer_20210306D1/tensorboard/version_0\r\n",
      "/data/git/product-category/data/transformer_20210306D1/tensorboard/version_0/events.out.tfevents.1615082428.ip-10-0-3-91.31684.1\r\n",
      "/data/git/product-category/data/transformer_20210306D1/tensorboard/version_0/hparams.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!find $p_out/ | grep *ckpt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pcmodel = PCModel.load_from_checkpoint(f'{p_out}/lightning_logs/version_1/checkpoints/epoch=6-step=17317.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hparams.yaml  metrics.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls $p_out/csv/version_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmtr = pd.read_csv(f\"{p_out}/csv/version_0/metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss_step</th>\n",
       "      <th>train_accu_step</th>\n",
       "      <th>gpu_id: 0/memory.used (MB)</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss_epoch</th>\n",
       "      <th>train_accu_epoch</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.188815</td>\n",
       "      <td>0.955995</td>\n",
       "      <td>16018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147974</td>\n",
       "      <td>0.963648</td>\n",
       "      <td>16018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137017</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>16018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102367</td>\n",
       "      <td>0.971301</td>\n",
       "      <td>16018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124449</td>\n",
       "      <td>0.974490</td>\n",
       "      <td>16018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>0.157963</td>\n",
       "      <td>0.959145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4784.0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099894</td>\n",
       "      <td>0.970332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss_step  train_accu_step  gpu_id: 0/memory.used (MB)  epoch  step  \\\n",
       "0         0.188815         0.955995                     16018.0      0    49   \n",
       "1         0.147974         0.963648                     16018.0      0    99   \n",
       "2         0.137017         0.959184                     16018.0      0   149   \n",
       "3         0.102367         0.971301                     16018.0      0   199   \n",
       "4         0.124449         0.974490                     16018.0      0   249   \n",
       "5              NaN              NaN                     16018.0      0   249   \n",
       "6              NaN              NaN                      4784.0      0   249   \n",
       "\n",
       "   train_loss_epoch  train_accu_epoch  valid_loss  valid_accu  \n",
       "0               NaN               NaN         NaN         NaN  \n",
       "1               NaN               NaN         NaN         NaN  \n",
       "2               NaN               NaN         NaN         NaN  \n",
       "3               NaN               NaN         NaN         NaN  \n",
       "4               NaN               NaN         NaN         NaN  \n",
       "5          0.157963          0.959145         NaN         NaN  \n",
       "6               NaN               NaN    0.099894    0.970332  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmtr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dl = data_module.val_dataloader()\n",
    "n=0\n",
    "for dat in dl:\n",
    "    input_ids, attention_mask, ys = dat\n",
    "    logits = pcmodel(input_ids, attention_mask)\n",
    "    accu = getaccu(logits, ys)\n",
    "    print(accu.item())\n",
    "    n+=1\n",
    "    if n>1: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcheckpoints\u001b[0m/  events.out.tfevents.1615059909.ip-10-0-3-91.12209.0  hparams.yaml\r\n"
     ]
    }
   ],
   "source": [
    "ls $p_out/lightning_logs/version_1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_demo(df):\n",
    "    i2cat = data_module.i2cat\n",
    "    tokenizer = data_module.tokenizer\n",
    "    max_seq_length = data_module.max_seq_length\n",
    "    row = df.sample()\n",
    "    display(row)\n",
    "    txt = list(row.txt.values)\n",
    "    input_ids, attention_mask = mk_tensors(txt, tokenizer, max_seq_length)\n",
    "    logits = pcmodel(input_ids, attention_mask)[0]\n",
    "    print('Truth:', sorted(o for o in row.category.values[0].split('|') if o in i2cat))\n",
    "\n",
    "    top_icats = np.argsort(-logits.detach().numpy())[:5]\n",
    "    print('Top Preds:',[i2cat[i] for i in top_icats])\n",
    "    print('Preds 0.5+:',[i2cat[i] for i in np.where(logits>0)[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>asin</th>\n",
       "      <th>domain</th>\n",
       "      <th>txt</th>\n",
       "      <th>is_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68562</th>\n",
       "      <td>Books|Children's Books|Animals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Happy: The Cavalier King Charles Spaniel</td>\n",
       "      <td>Kathleen Mary Clancy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1946300071</td>\n",
       "      <td>Book</td>\n",
       "      <td>Happy: The Cavalier King Charles Spaniel Kathl...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             category description  \\\n",
       "68562  Books|Children's Books|Animals         NaN   \n",
       "\n",
       "                                          title                 brand feature  \\\n",
       "68562  Happy: The Cavalier King Charles Spaniel  Kathleen Mary Clancy     NaN   \n",
       "\n",
       "             asin domain                                                txt  \\\n",
       "68562  1946300071   Book  Happy: The Cavalier King Charles Spaniel Kathl...   \n",
       "\n",
       "       is_validation  \n",
       "68562            1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: ['Animals', 'Books', \"Children's Books\"]\n",
      "Top Preds: ['Books', 'Literature &amp; Fiction', 'Literature & Fiction', 'Contemporary', 'Action &amp; Adventure']\n",
      "Preds 0.5+: ['Books']\n"
     ]
    }
   ],
   "source": [
    "do_demo(data_module.df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save to script"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "script = pcmodel.to_torchscript()\n",
    "# save for use in production environment\n",
    "torch.jit.save(script, f\"{p_out}/pcmodel.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  6 22:13:38 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   62C    P0    60W / 300W |   1972MiB / 16160MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     12209      C   ...conda3/envs/product-category/bin/python  1961MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "product-category",
   "language": "python",
   "name": "product-category"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
